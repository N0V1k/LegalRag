{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unsloth\n",
    "\n",
    "!pip install -q -U bitsandbytes==0.45.3\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bd0f5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 8096 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f649a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('test_df').drop('Unnamed: 0', axis=1)\n",
    "train_df = pd.read_csv('train_df').drop('Unnamed: 0', axis=1)\n",
    "eval_df = pd.read_csv('eval_df').drop('Unnamed: 0', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54deda58",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = eval_df.sample(frac=1, random_state=42)\n",
    "train_df = train_df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb84ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = True,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 32, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a33293",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_format = \"\"\"–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è, –æ–ø–∏—Å—ã–≤–∞—é—â–∞—è –∑–∞–¥–∞—á—É, –≤ —Å–æ—á–µ—Ç–∞–Ω–∏–∏ —Å –≤–≤–æ–¥–æ–º, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç. \n",
    "–ù–∞–ø–∏—à–∏ –æ—Ç–≤–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å.\n",
    "\n",
    "### Instruction:\n",
    "–¢—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç. –¢–µ–±–µ –¥–∞–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–∏—Ç—É–∞—Ü–∏–∏, –≤ –∫–æ—Ç–æ—Ä–æ–π —Ç—ã –¥–æ–ª–∂–µ–Ω —Ö–æ—Ä–æ—à–æ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è \n",
    "–∏ –¥–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–π, –Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å.\n",
    "\n",
    "### Input:\n",
    "–ö–æ–Ω—Ç–µ–∫—Å—Ç: {}\n",
    "\n",
    "–í–æ–ø—Ä–æ—Å: {}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe449bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    contexts   = examples[\"–ö–æ–Ω—Ç–µ–∫—Å—Ç\"]\n",
    "    questions  = examples[\"–í–æ–ø—Ä–æ—Å\"]\n",
    "    outputs    = examples[\"–û—Ç–≤–µ—Ç\"]\n",
    "    texts      = []\n",
    "    for context, question, output in zip(contexts, questions, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = prompt_format.format(context, question, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10508b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>–ö–æ–Ω—Ç–µ–∫—Å—Ç</th>\n",
       "      <th>–í–æ–ø—Ä–æ—Å</th>\n",
       "      <th>–û—Ç–≤–µ—Ç</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ò—Å—Ç–µ—Ü —è–≤–ª—è–µ—Ç—Å—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–º –∫–æ–º–Ω–∞—Ç—ã –≤ –∫–æ–º–º—É–Ω–∞...</td>\n",
       "      <td>–ö–∞–∫–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –º–Ω–µ –Ω—É–∂–Ω—ã –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω...</td>\n",
       "      <td>–ù–µ–æ–±—Ö–æ–¥–∏–º—ã:  \\n- –ó–∞–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–π –æ—Ü–µ–Ω–∫–∏...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–ü–µ—à–µ—Ö–æ–¥ (–§–ò–û1) –±—ã–ª –æ—à—Ç—Ä–∞—Ñ–æ–≤–∞–Ω –Ω–∞ 500 —Ä—É–±–ª–µ–π –∑–∞...</td>\n",
       "      <td>–ú–æ–∂–Ω–æ –ª–∏ –∏–∑–±–µ–∂–∞—Ç—å —à—Ç—Ä–∞—Ñ–∞, –µ—Å–ª–∏ –ø–µ—à–µ—Ö–æ–¥–Ω—ã–π –ø–µ—Ä–µ...</td>\n",
       "      <td>–ù–µ—Ç, –ø. 4.3 –ü–î–î –æ–±—è–∑—ã–≤–∞–µ—Ç –ø–µ—à–µ—Ö–æ–¥–æ–≤ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–°—Ç—Ä–∞—Ö–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è –°–ü–ê–û ¬´–ò–Ω–≥–æ—Å—Å—Ç—Ä–∞—Ö¬ª –≤—ã–ø–ª–∞—Ç–∏–ª–∞...</td>\n",
       "      <td>–ß—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ —Å—Ç—Ä–∞—Ö–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç...</td>\n",
       "      <td>–¢—Ä–µ–±—É–π—Ç–µ –æ—Ç —Å—Ç—Ä–∞—Ö–æ–≤—â–∏–∫–∞ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –≤–∞—à–µ–≥–æ —É...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–í–æ–¥–∏—Ç–µ–ª—å (–∏—Å—Ç–µ—Ü) —Å–æ–≤–µ—Ä—à–∏–ª –Ω–∞–µ–∑–¥ –Ω–∞ —Å—Ç–æ—è—â–∏–π –∞–≤—Ç...</td>\n",
       "      <td>–ú–æ–∂–Ω–æ –ª–∏ –∏–∑–±–µ–∂–∞—Ç—å –ª–∏—à–µ–Ω–∏—è –ø—Ä–∞–≤, –µ—Å–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω...</td>\n",
       "      <td>–í–æ–∑–º–æ–∂–Ω–æ, –Ω–æ –º–∞–ª–æ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å—Ç. 2.9 –ö–æ–ê–ü ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–û–û–û ¬´–Æ—Ä—ç–Ω–µ—Ä–≥–æ–∫–æ–Ω—Å–∞–ª—Ç¬ª –±—ã–ª–æ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–æ –∫ –∞–¥–º–∏–Ω–∏...</td>\n",
       "      <td>–ú–æ–∂–Ω–æ –ª–∏ –æ—Å–ø–æ—Ä–∏—Ç—å —à—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ...</td>\n",
       "      <td>–î–∞, –º–æ–∂–Ω–æ. –ï—Å–ª–∏ –ø—Ä–µ–¥–ø–∏—Å–∞–Ω–∏–µ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ—Å–Ω–æ–≤–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11323</th>\n",
       "      <td>–Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ –û–û–û ¬´–ö—Ä–∞—Å–∫–æ–º¬ª –±—ã–ª–æ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–æ...</td>\n",
       "      <td>–ú–æ–∂–µ—Ç –ª–∏ –Ω–µ–∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–∏—Å–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∞ –ø–æ–∂–∞—Ä...</td>\n",
       "      <td>–î–∞, –µ—Å–ª–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø–æ–∂–∞—Ä–Ω–æ–π –±–µ–∑–æ–ø–∞—Å...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11324</th>\n",
       "      <td>–î–∏—Ä–µ–∫—Ç–æ—Ä –û–û–û ¬´–ê—Ç–ª–∞–Ω—Ç¬ª –±—ã–ª –ø—Ä–∏–≤–ª–µ—á–µ–Ω –∫ –∞–¥–º–∏–Ω–∏—Å—Ç...</td>\n",
       "      <td>–ú–æ–∂–Ω–æ –ª–∏ –∏–∑–±–µ–∂–∞—Ç—å —à—Ç—Ä–∞—Ñ–∞, –µ—Å–ª–∏ –ø—Ä–∞–≤–æ–Ω–∞—Ä—É—à–µ–Ω–∏–µ ...</td>\n",
       "      <td>–î–∞, –≤–æ–∑–º–æ–∂–Ω–æ. –°–æ–≥–ª–∞—Å–Ω–æ —á. 1 —Å—Ç. 4.1.1 –ö–æ–ê–ü –†–§,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11325</th>\n",
       "      <td>–î–æ—Ä–æ–∂–Ω–æ-—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–µ –ø—Ä–æ–∏—Å—à–µ—Å—Ç–≤–∏–µ –ø—Ä–æ–∏–∑–æ—à–ª–æ –º–µ...</td>\n",
       "      <td>–ö—Ç–æ –Ω–µ—Å–µ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ –≤—Ä–µ–¥, –µ—Å–ª–∏ –∞–≤—Ç–æ–º–æ...</td>\n",
       "      <td>–ü–æ —Å—Ç. 1079 –ì–ö –†–§ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ—Å–µ—Ç –≤–ª–∞–¥–µ–ª...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11326</th>\n",
       "      <td>–í –º–∞–µ 2023 –≥–æ–¥–∞ –ø—Ä–æ–∏–∑–æ—à–ª–æ –î–¢–ü –ø–æ –≤–∏–Ω–µ –≤–æ–¥–∏—Ç–µ–ª—è...</td>\n",
       "      <td>–ú–æ–∂–Ω–æ –ª–∏ –≤–∑—ã—Å–∫–∞—Ç—å –Ω–µ—É—Å—Ç–æ–π–∫—É –∑–∞ –ø—Ä–æ—Å—Ä–æ—á–∫—É —Å—Ç—Ä–∞—Ö...</td>\n",
       "      <td>–î–∞, –ø–æ –ø. 21 —Å—Ç. 12 –ó–∞–∫–æ–Ω–∞ –æ–± –û–°–ê–ì–û –Ω–µ—É—Å—Ç–æ–π–∫–∞ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11327</th>\n",
       "      <td>–ò—Å—Ç–µ—Ü –≤–ª–∞–¥–µ–µ—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–º Kia Rio, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–ª...</td>\n",
       "      <td>–ú–æ–≥—É –ª–∏ —è –≤–∑—ã—Å–∫–∞—Ç—å —Å –≤–∏–Ω–æ–≤–Ω–∏–∫–∞ –î–¢–ü —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂...</td>\n",
       "      <td>–î–∞, —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç. 1072 –ì–ö –†–§, –µ—Å–ª–∏ —Å—Ç—Ä–∞—Ö–æ–≤–æ–≥–æ –≤...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11328 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                –ö–æ–Ω—Ç–µ–∫—Å—Ç  \\\n",
       "0      –ò—Å—Ç–µ—Ü —è–≤–ª—è–µ—Ç—Å—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–º –∫–æ–º–Ω–∞—Ç—ã –≤ –∫–æ–º–º—É–Ω–∞...   \n",
       "1      –ü–µ—à–µ—Ö–æ–¥ (–§–ò–û1) –±—ã–ª –æ—à—Ç—Ä–∞—Ñ–æ–≤–∞–Ω –Ω–∞ 500 —Ä—É–±–ª–µ–π –∑–∞...   \n",
       "2      –°—Ç—Ä–∞—Ö–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è –°–ü–ê–û ¬´–ò–Ω–≥–æ—Å—Å—Ç—Ä–∞—Ö¬ª –≤—ã–ø–ª–∞—Ç–∏–ª–∞...   \n",
       "3      –í–æ–¥–∏—Ç–µ–ª—å (–∏—Å—Ç–µ—Ü) —Å–æ–≤–µ—Ä—à–∏–ª –Ω–∞–µ–∑–¥ –Ω–∞ —Å—Ç–æ—è—â–∏–π –∞–≤—Ç...   \n",
       "4      –û–û–û ¬´–Æ—Ä—ç–Ω–µ—Ä–≥–æ–∫–æ–Ω—Å–∞–ª—Ç¬ª –±—ã–ª–æ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–æ –∫ –∞–¥–º–∏–Ω–∏...   \n",
       "...                                                  ...   \n",
       "11323  –Æ—Ä–∏–¥–∏—á–µ—Å–∫–æ–µ –ª–∏—Ü–æ –û–û–û ¬´–ö—Ä–∞—Å–∫–æ–º¬ª –±—ã–ª–æ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–æ...   \n",
       "11324  –î–∏—Ä–µ–∫—Ç–æ—Ä –û–û–û ¬´–ê—Ç–ª–∞–Ω—Ç¬ª –±—ã–ª –ø—Ä–∏–≤–ª–µ—á–µ–Ω –∫ –∞–¥–º–∏–Ω–∏—Å—Ç...   \n",
       "11325  –î–æ—Ä–æ–∂–Ω–æ-—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–µ –ø—Ä–æ–∏—Å—à–µ—Å—Ç–≤–∏–µ –ø—Ä–æ–∏–∑–æ—à–ª–æ –º–µ...   \n",
       "11326  –í –º–∞–µ 2023 –≥–æ–¥–∞ –ø—Ä–æ–∏–∑–æ—à–ª–æ –î–¢–ü –ø–æ –≤–∏–Ω–µ –≤–æ–¥–∏—Ç–µ–ª—è...   \n",
       "11327  –ò—Å—Ç–µ—Ü –≤–ª–∞–¥–µ–µ—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–º Kia Rio, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–ª...   \n",
       "\n",
       "                                                  –í–æ–ø—Ä–æ—Å  \\\n",
       "0      –ö–∞–∫–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –º–Ω–µ –Ω—É–∂–Ω—ã –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω...   \n",
       "1      –ú–æ–∂–Ω–æ –ª–∏ –∏–∑–±–µ–∂–∞—Ç—å —à—Ç—Ä–∞—Ñ–∞, –µ—Å–ª–∏ –ø–µ—à–µ—Ö–æ–¥–Ω—ã–π –ø–µ—Ä–µ...   \n",
       "2      –ß—Ç–æ –¥–µ–ª–∞—Ç—å, –µ—Å–ª–∏ —Å—Ç—Ä–∞—Ö–æ–≤–∞—è –∫–æ–º–ø–∞–Ω–∏—è —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç...   \n",
       "3      –ú–æ–∂–Ω–æ –ª–∏ –∏–∑–±–µ–∂–∞—Ç—å –ª–∏—à–µ–Ω–∏—è –ø—Ä–∞–≤, –µ—Å–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω...   \n",
       "4      –ú–æ–∂–Ω–æ –ª–∏ –æ—Å–ø–æ—Ä–∏—Ç—å —à—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ...   \n",
       "...                                                  ...   \n",
       "11323  –ú–æ–∂–µ—Ç –ª–∏ –Ω–µ–∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–∏—Å–∞–Ω–∏—è –æ—Ä–≥–∞–Ω–∞ –ø–æ–∂–∞—Ä...   \n",
       "11324  –ú–æ–∂–Ω–æ –ª–∏ –∏–∑–±–µ–∂–∞—Ç—å —à—Ç—Ä–∞—Ñ–∞, –µ—Å–ª–∏ –ø—Ä–∞–≤–æ–Ω–∞—Ä—É—à–µ–Ω–∏–µ ...   \n",
       "11325  –ö—Ç–æ –Ω–µ—Å–µ—Ç –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∑–∞ –≤—Ä–µ–¥, –µ—Å–ª–∏ –∞–≤—Ç–æ–º–æ...   \n",
       "11326  –ú–æ–∂–Ω–æ –ª–∏ –≤–∑—ã—Å–∫–∞—Ç—å –Ω–µ—É—Å—Ç–æ–π–∫—É –∑–∞ –ø—Ä–æ—Å—Ä–æ—á–∫—É —Å—Ç—Ä–∞—Ö...   \n",
       "11327  –ú–æ–≥—É –ª–∏ —è –≤–∑—ã—Å–∫–∞—Ç—å —Å –≤–∏–Ω–æ–≤–Ω–∏–∫–∞ –î–¢–ü —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂...   \n",
       "\n",
       "                                                   –û—Ç–≤–µ—Ç  \n",
       "0      –ù–µ–æ–±—Ö–æ–¥–∏–º—ã:  \\n- –ó–∞–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–π –æ—Ü–µ–Ω–∫–∏...  \n",
       "1      –ù–µ—Ç, –ø. 4.3 –ü–î–î –æ–±—è–∑—ã–≤–∞–µ—Ç –ø–µ—à–µ—Ö–æ–¥–æ–≤ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å...  \n",
       "2      –¢—Ä–µ–±—É–π—Ç–µ –æ—Ç —Å—Ç—Ä–∞—Ö–æ–≤—â–∏–∫–∞ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –≤–∞—à–µ–≥–æ —É...  \n",
       "3      –í–æ–∑–º–æ–∂–Ω–æ, –Ω–æ –º–∞–ª–æ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å—Ç. 2.9 –ö–æ–ê–ü ...  \n",
       "4      –î–∞, –º–æ–∂–Ω–æ. –ï—Å–ª–∏ –ø—Ä–µ–¥–ø–∏—Å–∞–Ω–∏–µ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ—Å–Ω–æ–≤–∞...  \n",
       "...                                                  ...  \n",
       "11323  –î–∞, –µ—Å–ª–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø–æ–∂–∞—Ä–Ω–æ–π –±–µ–∑–æ–ø–∞—Å...  \n",
       "11324  –î–∞, –≤–æ–∑–º–æ–∂–Ω–æ. –°–æ–≥–ª–∞—Å–Ω–æ —á. 1 —Å—Ç. 4.1.1 –ö–æ–ê–ü –†–§,...  \n",
       "11325  –ü–æ —Å—Ç. 1079 –ì–ö –†–§ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ—Å–µ—Ç –≤–ª–∞–¥–µ–ª...  \n",
       "11326  –î–∞, –ø–æ –ø. 21 —Å—Ç. 12 –ó–∞–∫–æ–Ω–∞ –æ–± –û–°–ê–ì–û –Ω–µ—É—Å—Ç–æ–π–∫–∞ ...  \n",
       "11327  –î–∞, —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç. 1072 –ì–ö –†–§, –µ—Å–ª–∏ —Å—Ç—Ä–∞—Ö–æ–≤–æ–≥–æ –≤...  \n",
       "\n",
       "[11328 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.reset_index().drop('index', axis=1)\n",
    "eval_df = eval_df.reset_index().drop('index', axis=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "eval_ds = Dataset.from_pandas(eval_df)\n",
    "test_ds = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2533f34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/11328 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11328/11328 [00:00<00:00, 41642.08 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 297/297 [00:00<00:00, 35614.05 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:00<00:00, 39893.83 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(formatting_prompts_func, batched = True)\n",
    "eval_ds = eval_ds.map(formatting_prompts_func, batched = True)\n",
    "test_ds = test_ds.map(formatting_prompts_func, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "LEARNING_RATE = 2e-4\n",
    "TRAIN_STEPS = 500\n",
    "TRAIN_EPOCHS = 3\n",
    "OUTPUT_DIR = \"./QLoRA_64_2_3\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size = BATCH_SIZE,\n",
    "    gradient_accumulation_steps = GRADIENT_ACCUMULATION_STEPS,\n",
    "    warmup_steps = 50,\n",
    "    num_train_epochs = TRAIN_EPOCHS, # Set this for 1 full training run.\n",
    "    #max_steps = TRAIN_STEPS,\n",
    "    learning_rate = LEARNING_RATE,\n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    logging_steps = 1,\n",
    "    eval_strategy = \"steps\",\n",
    "    save_strategy = \"steps\",\n",
    "    eval_steps = 1,\n",
    "    save_steps = 1,\n",
    "    save_total_limit = 3,\n",
    "    load_best_model_at_end = True,\n",
    "    optim = \"adamw_8bit\",\n",
    "    weight_decay = 0.01,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    seed = 3407,\n",
    "    output_dir = OUTPUT_DIR,\n",
    "    report_to = \"wandb\" #\"tensorboard\", # Use this for WandB etc\n",
    "    # overwrite_output_dir=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553081d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11328/11328 [00:06<00:00, 1663.26 examples/s]\n",
      "Unsloth: Tokenizing [\"text\"] (num_proc=2): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 297/297 [00:01<00:00, 235.45 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_ds,\n",
    "    eval_dataset = eval_ds,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 2048,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ed5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee69a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61732f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./qlora_64_2_3\") \n",
    "tokenizer.save_pretrained(\"./qlora_64_2_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(\"foxxar04/llama_qlora\")\n",
    "tokenizer.push_to_hub(\"foxxar04/llama_qlora\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
